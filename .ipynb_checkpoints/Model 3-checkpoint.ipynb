{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "retained-florida",
   "metadata": {},
   "source": [
    "# Training Model-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-fluid",
   "metadata": {},
   "source": [
    "## Importing Data and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "trying-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import plotly.graph_objects as go \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fixed-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "nab = Path.cwd()/'NAB'\n",
    "data_path = nab/'data'\n",
    "labels_filepath = nab/'labels/combined_labels.json'\n",
    "\n",
    "training_filename = 'realAWSCloudwatch/rds_cpu_utilization_cc0c53.csv'\n",
    "\n",
    "valid_filename = 'realAWSCloudwatch/rds_cpu_utilization_e47b3b.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mounted-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(labels_filepath, 'r') as f:\n",
    "    anomalies_timestamps = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accessory-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path/training_filename)\n",
    "valid = pd.read_csv(data_path/valid_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-seeking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model-1 Autoregression statistical model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "identical-maple",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c945e88535c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCPUDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stand_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class CPUDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, size: int):\n",
    "        self.chunks = torch.FloatTensor(data['stand_value']).unfold(0, size, size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.chunks.size(0)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x = self.chunks[i]\n",
    "        return x\n",
    "\n",
    "train_ds = CPUDataset(train, 64)\n",
    "valid_ds = CPUDataset(valid, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "personal-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, device):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(in_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, out_size)\n",
    "        self.device = device\n",
    "        self.init_hidden()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, self.hidden_state = self.lstm(\n",
    "            x.view(len(x), 1, -1), self.hidden_state\n",
    "        )\n",
    "        self.hidden_state = tuple(\n",
    "            [h.detach() for h in self.hidden_state]\n",
    "        )\n",
    "        out = out.view(len(x), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        self.hidden_state = (\n",
    "            torch.zeros((1, 1, self.hidden_size)).to(self.device),\n",
    "            torch.zeros((1, 1, self.hidden_size)).to(self.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-latino",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarabnidhaan/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "def train_model(model: LSTMModel, dataloaders: dict, optimizer: opt.Optimizer, \n",
    "                scheduler, criterion, device: torch.device, epochs: int):\n",
    "    losses_data = {'train': [], 'valid': []}\n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f'Epoch {epoch}/{epochs-1}')\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_total = 0.\n",
    "            \n",
    "        # Here changes start\n",
    "            for idx, sequence in enumerate(dataloaders[phase]):\n",
    "                value = sequence\n",
    "                value = value.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    out = model(value.view(-1, 1))\n",
    "                    loss = criterion(out.view(-1), value.view(-1))\n",
    "        # Here changes end\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "\n",
    "                running_loss += loss.item() * out.size(0)\n",
    "                running_total += out.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / running_total\n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss}')\n",
    "            losses_data[phase].append(epoch_loss)\n",
    "    return losses_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch_count = 50\n",
    "model = LSTMModel(1, 128, 1, device)\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_ds, batch_size=1),\n",
    "    'valid': DataLoader(valid_ds, batch_size=1)\n",
    "}\n",
    "optim = opt.Adam(params=model.parameters(), lr=1e-3)\n",
    "sched = opt.lr_scheduler.OneCycleLR(\n",
    "  optim, max_lr=1e-3, steps_per_epoch=len(dataloaders['train']), epochs=total_epoch_count\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train_model(model, dataloaders, optim, sched, criterion, device, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = dict(xaxis=dict(title='Epoch'), yaxis=dict(title='Loss'))\n",
    "fig = go.Figure(layout=layout)\n",
    "fig.add_trace(go.Scatter(y=losses['train'], mode='lines', name='Train Loss',))\n",
    "fig.add_trace(go.Scatter(y=losses['valid'], mode='lines', name='Valid Loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = train['stand_value'].values.astype(np.float32).flatten()\n",
    "valid_values = valid['stand_value'].values.astype(np.float32).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    res_train = model(torch.tensor(train_values).to(device))\n",
    "res_train = res_train.cpu()\n",
    "with torch.no_grad():\n",
    "    res_valid = model(torch.tensor(valid_values).to(device))\n",
    "res_valid = res_valid.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-stupid",
   "metadata": {},
   "source": [
    "### Model-1 Graph-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=pd.DataFrame(res_train.numpy())\n",
    "layout = dict(xaxis=dict(title='Timestamp'), yaxis=dict(title='CPU Utilization')) \n",
    "\n",
    "fig = go.Figure(layout=layout) \n",
    "\n",
    "fig.add_trace(go.Scatter(x=train['timestamp'], y=train['stand_value'], \n",
    "                         mode='markers', name='Ground Truth',\n",
    "                         marker=dict(color='blue')))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=train['timestamp'],\n",
    "                         y=train1[0], \n",
    "                         mode='markers', name='Predicted Value',\n",
    "                         marker=dict(color='orange')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-framing",
   "metadata": {},
   "source": [
    "### Model-3 Graph-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid1=pd.DataFrame(res_valid.numpy())\n",
    "layout = dict(xaxis=dict(title='Timestamp'), yaxis=dict(title='CPU Utilization')) \n",
    "\n",
    "fig = go.Figure(layout=layout) \n",
    "\n",
    "fig.add_trace(go.Scatter(x=valid['timestamp'], y=valid['stand_value'], \n",
    "                         mode='markers', name='Ground Truth',\n",
    "                         marker=dict(color='blue')))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=valid['timestamp'],\n",
    "                         y=valid1[0], \n",
    "                         mode='markers', name='Predicted Value',\n",
    "                         marker=dict(color='orange')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
